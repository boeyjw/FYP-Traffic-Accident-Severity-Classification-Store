install.packages("neuralnet, leaflet")
install.packages("neuralnet")
install.packages("leaflet")
library(installr)
installr()
installr()
sample
help(sample)
help(iris)
help(iris3)
iris3
hist
hist(iris)
Sepal.length
Sepal.Length
iris.Sepal.Length
s <- sample(iris)
count.fields(iris)
length(iris)
length(s)
r(iris)
row
row(iris)
s <- sample(iris, .8)
s <- sample(iris, 100)
s <- sample(iris, 4)
s <- sample(iris, 2)
s <- sample(iris, 5)
remove(s)
tree
trees
decision
plot()
ir <- iris
remove(ir)
plot(iris$Sepal.Length, iris$Petal.Length)
help(hist)
wd
help("scatter.smooth")
help("sunflowerplot")
sunflowerplot(x = iris$Sepal.Length, y = iris$Sepal.Width)
sunflowerplot(x = iris$Sepal.Length)
sunflowerplot(x = iris$Sepal.Widt)
sunflowerplot(x = iris$Sepal.Width)
sunflowerplot(x = iris$Petal.Length)
sunflowerplot(x = iris$Petal.Width)
libra
library(party)
help(ctree)
col(iris)
head(iris)
ctree(formula = Species ~ Petal.Length + Petal.Width, data = iris)
plot(ctree(formula = Species ~ Petal.Length + Petal.Width, data = iris))
library(caret)
install.packages("caret")
devtools::install_github("rstudio/keras")
install.packages("devtools")
devtools::install_github("rstudio/keras")
devtools::install_github("rstudio/keras")
library(RTools)
devtools::install_github("rstudio/keras")
remove.packages(keras)
remove.packages(:)
remove.packages("keras")
load("~/Dataset/UK_Car_Accidents_1979-2016/alldataloaded_proccessed.RData")
common <- intersect(Accidents2016, Casualties2016)
remove(common)
cac2016 <- intersect(Accidents2016$Accident_Index, Casualties2016$Accident_Index)
cac2016
cav2016 <- intersect(Accidents2016, Vehicles2016)
remove(cav2016)
cav2016 <- intersect(Accidents2016$Accident_Index, Vehicles2016$Accident_Index)
c2016 <- intersect(cac2016, cav2016)
c2016
install.packages('dplyr')
quit
quit()
x <- c(0,0,0,0,1,1,1,1,1,1,1,2,2,2,2,3,3,3,0,0,0,0)
p <- matrix(nrow = 4, ncol = 4, 0)
for (t in 1:(length(x) - 1)) p[x[t], x[t + 1]] <- p[x[t], x[t + 1]] + 1
for (i in 1:4) p[i, ] <- p[i, ] / sum(p[i, ])
p
x <- c(0,0,0,0,1,1,1,1,1,1,1,2,2,2,2,3,3,3,0,0,0,0)
p <- matrix(nrow = 4, ncol = 4, 0)
for (t in 1:(length(x) - 1)) p[x[t], x[t + 1]] <- p[x[t], x[t + 1]] + 1
for (i in 0:3) p[i, ] <- p[i, ] / sum(p[i, ])
p
p[1, ]
library(parallel)
cores_2_use <- detectCores() - 3
cl <- makeCluster(cores_2_use)
fun_imp <- function(cl, data, tar = NA, X = 1:detectCores() - 2, m = 1, imp_meth, pred_mat, maxit = 5) {
imp_pairs <- parLapply(cl = cl, X = X, fun = function(no, d, m, method, predictionMatrix, maxit) {
mice(d, m = m, printFlag = FALSE, method = method, maxit = maxit, predictorMatrix = predictionMatrix)
}, data[[n]], m, imp_meth, pred_mat, maxit)
imp_merge <<- imp_pairs[[1]]
for (p in 2:length(imp_pairs)) {
imp_merge <<- ibind(imp_merge, imp_pairs[[p]])
}
}
setwd('h:/gbaccident0516/')
acc <- read.csv('acc2005_2016-v2018.2.1-tobeimp.csv')
View(acc)
excl <- acc[,8:13]
acc <- acc[, !(names(acc) %in% names(excl))]
acc <- as.factor(acc)
acc <- lapply(acc, as.factor)
length(acc)
nrow(acc)
remove(excl)
acc <- read.csv('acc2005_2016-v2018.2.1-tobeimp.csv')
excl <- acc[, 8:13]
library(dplyr)
acc <- acc[, !(names(acc) %in% names(excl))]
acc <- bind_cols(acc, excl$Year)
?data.frame
acc <- bind_cols(acc, data.frame(Year = excl$Year))
acc <- split(acc, acc$Year)
?randu
?runif
runif(n = 100, min = 5, max = 200)
ceiling(runif(n = 100, min = 5, max = 200))
unique(ceiling(runif(n = 100, min = 5, max = 200)))
?sample
sample(10,10)
sample(10,10,replace=TRUE)
sample(10,10)
sample(8,10)
c(sample(10,10))
acc[[1]][c(sample(10,10)),]
nrow(acc[[1]])
tmp <- lapply(acc, function(x) x[sample(15000, nrow(x)),])
sample(10,5)
sample(5,10)
tmp <- lapply(acc, function(x) x[sample(nrow(x), 15000),])
?unsplit
tmp <- unsplit(tmp, Year)
tmp <- unsplit(tmp, tmp$Year)
tmp <- lapply(acc, function(x) x[sample(nrow(x), 15000),])
tmp <- unsplit(tmp, tmp[[1]]$Year)
tmp <- lapply(acc, function(x) x[sample(nrow(x), 15000),])
tmp <- unsplit(tmp, 'Year')
tmp <- lapply(acc, function(x) x[sample(nrow(x), 15000),])
tmp <- unsplit(tmp, 'Year')
tmp <- lapply(acc, function(x) x[sample(nrow(x), 15000),])
tmp <- bind_rows(tmp)
unique(tmp$Year)
any(is.na(tmp))
tmp[tmp == -1] <- NA
any(is.na(tmp))
summary(tmp)
tmp <- tmp[, 1:7]
summary(tmp)
acc <- unsplit(acc, acc$Year)
acc <- read.csv('acc2005_2016-v2018.2.1-tobeimp.csv')
fun_imp
fun_imp <- function(cl, data, tar = NA, X = 1:detectCores() - 2, m = 1, imp_meth, pred_mat, maxit = 5) {
imp_data <- data[[1]][c(),]
print('Start Imputation')
for (n in 1:length(data)) {
imp_pairs <- parLapply(cl = cl, X = X, fun = function(no, d, m, method, predictionMatrix, maxit) {
mice(d, m = m, printFlag = FALSE, method = method, maxit = maxit, predictorMatrix = predictionMatrix)
}, data[[n]], m, imp_meth, pred_mat, maxit)
imp_merge <<- imp_pairs[[1]]
for (p in 2:length(imp_pairs)) {
imp_merge <<- ibind(imp_merge, imp_pairs[[p]])
}
imp_data <- rbind(imp_data, complete(imp_merge))
print(n)
}
if (!is.na(tar)) {
tar_col <- names(tar)
for (q in 1:length(tar)) {
imp_data[[tar_col[q]]] <- tar[, q]
}
}
return (imp_data)
}
fun_imp <- function(cl, data, X = 1:detectCores() - 2, m = 1, imp_meth, pred_mat, maxit = 5) {
imp_data <- data[[1]][c(),]
print('Start Imputation')
for (n in 1:length(data)) {
imp_pairs <- parLapply(cl = cl, X = X, fun = function(no, d, m, method, predictionMatrix, maxit) {
mice(d, m = m, printFlag = FALSE, method = method, maxit = maxit, predictorMatrix = predictionMatrix)
}, data[[n]], m, imp_meth, pred_mat, maxit)
imp_merge <<- imp_pairs[[1]]
for (p in 2:length(imp_pairs)) {
imp_merge <<- ibind(imp_merge, imp_pairs[[p]])
}
imp_data <- rbind(imp_data, complete(imp_merge))
print(n)
}
return (imp_data)
}
acc[acc == -1] <- NA
summary(acc)
excl <- acc[, 8:length(acc)]
acc <- acc[, !(names(acc) %in% names(excl))]
tmp <- acc[sample(nrow(acc), 150000),]
summary(tmp)
acc <- bind_cols(acc, excl$Year)
acc <- bind_cols(acc, data.frame(Year = excl$Year))
tmp <- acc[sample(nrow(acc), 150000),]
summary(tmp)
tmp <- split(tmp, tmp$Year)
tmp <- lapply(tmp, tmp[,1:7])
tmp <- lapply(tmp, function(x) x[,1:7])
tmp <- lapply(tmp, function(x) sapply(x, as.factor))
acc[,1:7] <- as.factor(acc[,1:7])
acc[,1:7] <- sapply(acc[,1:7], as.factor)
acc[,1:7] <- sapply(acc[,1:7], factor)
acc$X1st_Road_Class <- factor(acc$X1st_Road_Class)
acc[,1:7] <- lapply(acc[,1:7], factor)
tmp <- acc[sample(nrow(acc), 150000),]
summary(tmp)
tmp <- acc[sample(nrow(acc), 150000),]
summary(tmp)
tmp <- split(tmp, tmp$Year)
tmp <- lapply(tmp, function(x) x[,1:7])
clusterSetRNGStream(cl, 500)
clusterExport(cl, 'tmp')
clusterEvalQ(cl, library(mice))
library(mice)
imp <- mice(tmp[[1]], maxit = 0)
imp$method
summary(tmp)
fun_imp(cl = cl, data = tmp, X = 1:cores_2_use, m = 1, imp_meth = imp$method, pred_mat = imp$predictorMatrix, maxit = 10)
plot(imp)
plot(imp_merge)
imp_merge$chainVar
imp_merge$chainMean
meth <- imp$method
meth[3:6] <- 'pmm'
imp_complete <- fun_imp(cl = cl, data = tmp, X = 1:cores_2_use, m = 1, imp_meth = meth, pred_mat = imp$predictorMatrix, maxit = 10)
plot(imp_merge)
meth[3:6] <- 'lda'
any(is.na(imp_complete))
summary(imp_complete)
summary(bind_rows(tmp))
imp_complete <- fun_imp(cl = cl, data = tmp, X = 1:cores_2_use, m = 1, imp_meth = meth, pred_mat = imp$predictorMatrix, maxit = 10)
splt_acc <- split(acc, acc$Year)
tmp <- lapply(splt_acc, function(x) x[sample(nrow(x), 20000),])
summary(bind_rows(tmp))
tmp <- lapply(tmp, function(x) x[,1:7])
meth[3:6] <- 'pmm'
predmat <- imp$predictorMatrix
predmat
imp <- mice(acc, maxit = 0)
imp$method
summary(acc)
imp <- mice(bind_rows(tmp), maxit = 0)
imp$method
imp$predictorMatrix
pred <- imp$predictorMatrix
remove(pred)
meth <- imp$method
meth[3:6] <- 'pmm'
pred
predmat
predmat <- imp$predictorMatrix
predmat
predmat[c('Road_Surface_Conditions'), 'X1st_Road_Class'] <- 0
predmat['Special_Conditions_at_Site', 'Road_Type'] <- 0
predmat
imp_complete <- fun_imp(cl = cl, data = tmp, X = 1:cores_2_use, m = 1, imp_meth = meth, pred_mat = imp$predictorMatrix, maxit = 10)
plot(imp_merge)
fun_imp
fun_imp <- function(cl, data, X = 1:detectCores() - 2, m = 1, imp_meth, pred_mat, maxit = 5) {
imp_data <- data[[1]][c(),]
print('Start Imputation')
for (n in 1:length(data)) {
imp_pairs <- parLapply(cl = cl, X = X, fun = function(no, d, m, method, predictionMatrix, maxit) {
mice(d, m = m, printFlag = FALSE, method = method, maxit = maxit, predictorMatrix = predictionMatrix, seed = 500)
}, data[[n]], m, imp_meth, pred_mat, maxit)
imp_merge <<- imp_pairs[[1]]
for (p in 2:length(imp_pairs)) {
imp_merge <<- ibind(imp_merge, imp_pairs[[p]])
}
imp_data <- rbind(imp_data, complete(imp_merge))
print(n)
}
return (imp_data)
}
imp_complete <- fun_imp(cl = cl, data = tmp, X = 1:cores_2_use, m = 1, imp_meth = meth, pred_mat = imp$predictorMatrix, maxit = 10)
plot(imp_merge)
imp_merge$chainMean
fun_imp <- function(cl, data, X = 1:detectCores() - 2, m = 1, imp_meth, pred_mat, maxit = 5) {
imp_data <- data[[1]][c(),]
print('Start Imputation')
for (n in 1:length(data)) {
imp_pairs <- parLapply(cl = cl, X = X, fun = function(no, d, m, method, predictionMatrix, maxit) {
mice(d, m = m, printFlag = FALSE, method = method, maxit = maxit, predictorMatrix = predictionMatrix)
}, data[[n]], m, imp_meth, pred_mat, maxit)
imp_merge <<- imp_pairs[[1]]
for (p in 2:length(imp_pairs)) {
imp_merge <<- ibind(imp_merge, imp_pairs[[p]])
}
imp_data <- rbind(imp_data, complete(imp_merge))
print(n)
}
return (imp_data)
}
imp_complete <- fun_imp(cl = cl, data = tmp, X = 1:cores_2_use, m = 1, imp_meth = meth, pred_mat = imp$predictorMatrix, maxit = 10)
plot(imp_merge)
imp_merge$chainMean
predmat
stopCluster(cl)
library(parallel)
cores_2_use <- detectCores() - 3
cl <- makeCluster(cores_2_use)
clusterSetRNGStream(cl, 500)
clusterExport(cl, 'tmp')
clusterEvalQ(cl, library(mice))
imp_complete <- fun_imp(cl = cl, data = tmp, X = 1:cores_2_use, m = 1, imp_meth = meth, pred_mat = imp$predictorMatrix, maxit = 10)
plot(imp_merge)
imp_complete <- fun_imp(cl = cl, data = tmp, X = 1:cores_2_use, m = 1, imp_meth = meth, pred_mat = predmat, maxit = 10)
imp_merge$predictorMatrix
plot(imp_merge)
meth[3:6] <- 'lda'
imp_complete <- fun_imp(cl = cl, data = tmp, X = 1:cores_2_use, m = 1, imp_meth = meth, pred_mat = imp$predictorMatrix, maxit = 10)
plot(imp_merge)
imp_complete <- fun_imp(cl = cl, data = tmp, X = 1:cores_2_use, m = 1, imp_meth = meth, pred_mat = predmat, maxit = 10)
plot(imp_merge)
densityplot(imp_merge)
densityplot(imp_merge, ~Junction_Detail + Road_Surface_Conditions)
densityplot(imp_merge, ~)
densityplot(imp_merge, )
names(imp_merge)
densityplot(imp_merge, ~Junction_Detail + Road_Surface_Conditions + Pedestrian_Crossing_Physical_Facilities + Special_Conditions_at_Site)
imp_complete <- fun_imp(cl = cl, data = tmp, X = 1:cores_2_use, m = 1, imp_meth = meth, pred_mat = imp$predictorMatrix, maxit = 10)
plot(imp_merge)
densityplot(imp_merge, ~Junction_Detail + Road_Surface_Conditions + Pedestrian_Crossing_Physical_Facilities + Special_Conditions_at_Site)
meth[3:6] <- 'pmm'
imp_complete <- fun_imp(cl = cl, data = tmp, X = 1:cores_2_use, m = 1, imp_meth = meth, pred_mat = imp$predictorMatrix, maxit = 10)
plot(imp_merge)
densityplot(imp_merge, ~Junction_Detail + Road_Surface_Conditions + Pedestrian_Crossing_Physical_Facilities + Special_Conditions_at_Site)
imp_complete <- fun_imp(cl = cl, data = tmp, X = 1:cores_2_use, m = 1, imp_meth = meth, pred_mat = predmat, maxit = 10)
plot(imp_merge)
densityplot(imp_merge, ~Junction_Detail + Road_Surface_Conditions + Pedestrian_Crossing_Physical_Facilities + Special_Conditions_at_Site)
meth[3:6] <- 'cart'
meth[3:6] <- 'polyreg'
imp_complete <- fun_imp(cl = cl, data = tmp, X = 1:cores_2_use, m = 1, imp_meth = meth, pred_mat = imp$predictorMatrix, maxit = 10)
plot(imp_merge)
densityplot(imp_merge, ~Junction_Detail + Road_Surface_Conditions + Pedestrian_Crossing_Physical_Facilities + Special_Conditions_at_Site)
imp_complete <- fun_imp(cl = cl, data = tmp, X = 1:cores_2_use, m = 1, imp_meth = meth, pred_mat = predmat, maxit = 10)
plot(imp_merge)
densityplot(imp_merge, ~Junction_Detail + Road_Surface_Conditions + Pedestrian_Crossing_Physical_Facilities + Special_Conditions_at_Site)
predmat
stopCluster(cl)
remove(acc, excl, imp, imp_complete, imp_merge, splt_acc, tmp, meth)
library(parallel)
cores_2_use <- detectCores() - 3
cl <- makeCluster(cores_2_use)
fun_imp
acc <- read.csv('acc2005_2016-v2018.2.1-tobeimp.csv')
clusterExport(cl, 'acc')
clusterEvalQ(cl, library(mice))
excl <- acc[, 8:13]
acc <- acc[, !(names(acc) %in% names(excl))]
acc <- bind_cols(acc, data.frame(Year = excl$Year))
acc <- split(acc, acc$Year)
acc <- read.csv('acc2005_2016-v2018.2.1-tobeimp.csv')
imp <- mice(acc, maxit = 0)
imp$method
acc[acc == -1] <- NA
imp <- mice(acc, maxit = 0)
imp <- mice(acc, maxit = 0)
acc <- acc[, !(names(acc) %in% names(excl))]
acc <- lapply(acc, factor)
nrow(acc)
acc <- bind_cols(acc, data.frame(Year = excl$Year))
acc <- acc[, !(names(acc) %in% names(excl))]
imp <- mice(acc, maxit = 0)
meth <- imp$method
predmat <- imp$predictorMatrix
meth
remove(imp)
acc <- bind_cols(acc, data.frame(Year = excl$Year))
acc <- split(acc, acc$Year)
stopCluster(cl)
acc <- lapply(acc, function(x) x[1:7])
tmp_acc <- lapply(acc, function(x) x[1:10000,])
clusterExport(cl = cl, 'tmp_acc')
cl <- makeCluster(5)
clusterExport(cl = cl, 'tmp_acc')
clusterEvalQ(cl = cl, library(mice))
runin <- function(data) {
imp_cplt <<- fun_imp(cl = cl, data = data, X = 1:cores_2_use, m = 2, imp_meth = meth, pred_mat = predmat, maxit = 10)
write.csv(x = imp_cplt, file = 'acc2005_2016-v2018.2.1.imp.csv', row.names = FALSE)
}
runin(tmp_acc)
clusterSetRNGStream(cl = cl, iseed = sample(123456789, 1))
runin(tmp_acc)
runin <- function(data) {
imp_cplt <<- fun_imp(cl = cl, data = data, X = 1:cores_2_use, m = 2, imp_meth = meth, pred_mat = predmat, maxit = 10)
write.csv(x = bind_cols(imp_cplt, excl), file = 'acc2005_2016-v2018.2.1.imp.csv', row.names = FALSE)
}
plot(imp_merge)
densityplot(imp_merge,)
imp_merge$method
densityplot(imp_merge, ~Road_Type+Junction_Detail+Pedestrian_Crossing_Physical_Facilities+Road_Surface_Conditions+Special_Conditions_at_Site)
densityplot(imp_merge, ~Road_Type + Junction_Detail + Pedestrian_Crossing_Physical_Facilities + Road_Surface_Conditions + Special_Conditions_at_Site)
densityplot(imp_merge, ~Junction_Detail + Pedestrian_Crossing_Physical_Facilities + Road_Surface_Conditions + Special_Conditions_at_Site)
remove(imp_cplt, imp_merge, tmp_acc)
stopCluster(cl)
cl <- makeCluster(5)
clusterSetRNGStream(cl = cl, iseed = sample(999999999, 1))
clusterEvalQ(cl = cl, library(mice))
library(dplyr)
clusterExport(cl = cl, 'acc')
runin
runin(acc)
plot(imp_merge)
im_merge$method
imp_merge$methods
imp_merge$method
densityplot(imp_merge, ~Junction_Detail + Pedestrian_Crossing_Physical_Facilities + Road_Surface_Conditions + Special_Conditions_at_Site)
stopCluster(cl)
library(saveRDS)
install.packages('saveRDS')
?save
save(imp_merge, file = 'acc_imp.RData')
?load
k <- load('acc_imp.RData')
k
save(list = 'imp_merge', file = 'acc_imp.RData')
k <- load('acc_imp.RData')
k$
e
k
saveRDS
?saveRDS
saveRDS(imp_merge, file = 'acc_imp.RData')
k <- readRDS('acc_imp.RData')
k == imp_merge
plot(k)
a <- complete(k)
fun_imp
a <- acc[[1]][c(),]
a <- rbind(a, complete(imp_merge))
a <- []
a <- list()
a[1] <- imp_merge
a
remove(a)
a[[1]] <- imp_merge
a <- vector('list', length(acc))
a[[1]] <- imp_merge
length(a)
a[[2]] <- predmat
a[[3]] <- acc
a[[2]]
fun_imp
fun_imp <- function(cl, data, X = 1:detectCores() - 2, m = 1, imp_meth, pred_mat, maxit = 5) {
imp_data <- data[[1]][c(),]
imp_merge <<- vector(mode = 'list', length = length(data))
print('Start Imputation')
for (n in 1:length(data)) {
imp_pairs <- parLapply(cl = cl, X = X, fun = function(no, d, m, method, predictionMatrix, maxit) {
mice(d, m = m, printFlag = FALSE, method = method, maxit = maxit, predictorMatrix = predictionMatrix)
}, data[[n]], m, imp_meth, pred_mat, maxit)
imp_merge[[n]] <<- imp_pairs[[1]]
for (p in 2:length(imp_pairs)) {
imp_merge[[n]] <<- ibind(imp_merge, imp_pairs[[p]])
}
imp_data <- rbind(imp_data, complete(imp_merge[[n]]))
print(n)
}
return (imp_data)
}
remove(a, excl, imp_cplt, k)
remove(imp_merge)
tmp <- lapply(acc, function(x) x[sample(nrow(x), 10000),])
imp <- mice(bind_rows(tmp), maxit = 0)
cl <- makeCluster(5)
clusterSetRNGStream(cl, 500)
clusterEvalQ(cl, library(mice))
summary(bind_rows(tmp))
imp$method
imp$predictorMatrix
runin
fun_imp
imp_cplt <- fun_imp(tmp)
imp_cplt <- fun_imp(cl = cl, data = tmp, X = 1:5, m = 2, imp_meth = imp$method, pred_mat = imp$predictorMatrix)
fun_imp
fun_imp <- function(cl, data, X = 1:detectCores() - 2, m = 1, imp_meth, pred_mat, maxit = 5) {
imp_data <- data[[1]][c(),]
imp_merge <<- vector(mode = 'list', length = length(data))
print('Start Imputation')
for (n in 1:length(data)) {
imp_pairs <- parLapply(cl = cl, X = X, fun = function(no, d, m, method, predictionMatrix, maxit) {
mice(d, m = m, printFlag = FALSE, method = method, maxit = maxit, predictorMatrix = predictionMatrix)
}, data[[n]], m, imp_meth, pred_mat, maxit)
imp_merge[[n]] <<- imp_pairs[[1]]
for (p in 2:length(imp_pairs)) {
imp_merge[[n]] <<- ibind(imp_merge[[n]], imp_pairs[[p]])
}
imp_data <- rbind(imp_data, complete(imp_merge[[n]]))
print(n)
}
return (imp_data)
}
meth[3:6] <- 'pmm'
imp_cplt <- fun_imp(cl = cl, data = tmp, X = 1:5, m = 2, imp_meth = imp$method, pred_mat = imp$predictorMatrix, maxit = 10)
imp_merge[[1]]$chainMean
lapply(imp_merge[[1]]$chainMean, mean)
type(imp_merge[[1]]$chainMean)
typeof(imp_merge[[1]]$chainMean)
stopCluster(cl)
k <- mean(imp_merge[[1]]$chainMean)
imp_merge[[1]]$chainMean
fun_imp
