demo()
graphics.table
graphics
demo(graphics)
smooth
par
cd
bar
plot
cls
clear
clean
sessionInfo()
graphics.graphics
graphics.image
plot(graphics.off())
Japanese()
Japanese
demo(graphics.Japanese)
demo(Japanese)
nlm()
help nlm
smooth
nlm
clean
clear
cls
empty
box
plot
histogram
hist
taylor
ts
matrix
byte
int
integer
string
str
float
double
Float
bigint
largeint
smallint
mini
max
min
max(4, 5)
max(4, 5, 22)
min(max(8, 11), avg(45, 55, 1, 2))
average
avg
avrg
min(max(8, 11), mean(45, 55, 1, 2))
mena
mean
quartile
quart
quar
vim
ggplot
shiny
exit
rshiny
vecp = rpois(100,5)
vecp = rpois(100,5)
vecp = rpois(100,5)
mean(vecp)
mean(vecp)
vecp = rpois(100,5)
mean(vecp)
rpois
lambda
set.seed(198911)
vecp = rpois(100,5)
mean(vecp)
vecp = rpois(100,5)
mean(vecp)
reps <- 5000
nexps <- 5
rate <- .1
set.seed(0)
system.time(x1 <- replicate(reps, sum(rexp(n=nexpsm rate=rate))))
system.time(x1 <- replicate(reps, sum(rexp(n=nexpsm, rate=rate))))
head(x1)
system.time(x1 <- replicate(reps, sum(rexp(n=nexpsm, rate=rate))))
qqplot
head
require(parallel)
system.time(x1 <- mclapply(1:reps, function(i) {}))
system.time(x1 <- mclapply(1:reps, function(i) {sum(rexp(n-nexps, rate=rate))}))
system.time(x1 <- mclapply(1:reps, function(i) {sum(rexp(n=nexps, rate=rate))}))
head(x1)
require(Biostrings)
install.packages("Biostrings")
require(MASS)
exit
quit
quit()
library(ggplot)
install.packages("ggplot, leaflet")
install.packages(ggplot)
install.packages("ggplot")
install.packages("leaflet")
plot
ggplot
version
library(readr)
train <- read_csv("D:/Download Placement/New folder/train.csv")
View(train)
ggplot2
install.packages(ggplot2)
install.packages("ggplot2")
dplyr
install.packages("shiny")
install.packages("data.table")
install.packages("zoo")
library("leaflet")
version
updare
update()
install.packages(c("haven", "R6", "Rcpp", "readr", "tibble"))
install.packages()
install.packages("installr")
library(installr)
updateR
updateR()
pathto
pathtor
install.packages("ggplot2")
install.packages("installr, ggplot2, dplyr, leaflet, zoo, data.table, R.matlab, matrix")
library(ggplot2)
install.packages("ggplot2")
install.packages("leaflet")
install.packages("dplyr")
install.packages("installr")
install.packages("zoo")
install.packages("data.tables")
install.packages("R.matlab")
install.packages("matrix")
install.packages("Matrix")
clc
clear
cls
clean
exit
quit()
setwd("D:\My Documents Placement\Dataset\Kaggle\UK_Car_Accidents_1979-2016")
install.packages("randomForest")
install.packages("party")
iris
print(head(iris))
library(randomForest)
library(party)
rf <- randomForest(Species ~ Sepal.length + Sepal.width + Petal.Length + Petal.Width, data = iris)
rf <- randomForest(Species ~ Sepal.Length + Sepal.Width + Petal.Length + Petal.Width, data = iris)
print(rf)
print(importance(fit, type = 2))
install.packages("neuralnet, leaflet")
install.packages("neuralnet")
install.packages("leaflet")
library(installr)
installr()
installr()
sample
help(sample)
help(iris)
help(iris3)
iris3
hist
hist(iris)
Sepal.length
Sepal.Length
iris.Sepal.Length
s <- sample(iris)
count.fields(iris)
length(iris)
length(s)
r(iris)
row
row(iris)
s <- sample(iris, .8)
s <- sample(iris, 100)
s <- sample(iris, 4)
s <- sample(iris, 2)
s <- sample(iris, 5)
remove(s)
tree
trees
decision
plot()
ir <- iris
remove(ir)
plot(iris$Sepal.Length, iris$Petal.Length)
help(hist)
wd
help("scatter.smooth")
help("sunflowerplot")
sunflowerplot(x = iris$Sepal.Length, y = iris$Sepal.Width)
sunflowerplot(x = iris$Sepal.Length)
sunflowerplot(x = iris$Sepal.Widt)
sunflowerplot(x = iris$Sepal.Width)
sunflowerplot(x = iris$Petal.Length)
sunflowerplot(x = iris$Petal.Width)
libra
library(party)
help(ctree)
col(iris)
head(iris)
ctree(formula = Species ~ Petal.Length + Petal.Width, data = iris)
plot(ctree(formula = Species ~ Petal.Length + Petal.Width, data = iris))
library(caret)
install.packages("caret")
devtools::install_github("rstudio/keras")
install.packages("devtools")
devtools::install_github("rstudio/keras")
devtools::install_github("rstudio/keras")
library(RTools)
devtools::install_github("rstudio/keras")
remove.packages(keras)
remove.packages(:)
remove.packages("keras")
load("~/Dataset/UK_Car_Accidents_1979-2016/alldataloaded_proccessed.RData")
common <- intersect(Accidents2016, Casualties2016)
remove(common)
cac2016 <- intersect(Accidents2016$Accident_Index, Casualties2016$Accident_Index)
cac2016
cav2016 <- intersect(Accidents2016, Vehicles2016)
remove(cav2016)
cav2016 <- intersect(Accidents2016$Accident_Index, Vehicles2016$Accident_Index)
c2016 <- intersect(cac2016, cav2016)
c2016
install.packages('dplyr')
quit
quit()
x <- c(0,0,0,0,1,1,1,1,1,1,1,2,2,2,2,3,3,3,0,0,0,0)
p <- matrix(nrow = 4, ncol = 4, 0)
for (t in 1:(length(x) - 1)) p[x[t], x[t + 1]] <- p[x[t], x[t + 1]] + 1
for (i in 1:4) p[i, ] <- p[i, ] / sum(p[i, ])
p
x <- c(0,0,0,0,1,1,1,1,1,1,1,2,2,2,2,3,3,3,0,0,0,0)
p <- matrix(nrow = 4, ncol = 4, 0)
for (t in 1:(length(x) - 1)) p[x[t], x[t + 1]] <- p[x[t], x[t + 1]] + 1
for (i in 0:3) p[i, ] <- p[i, ] / sum(p[i, ])
p
p[1, ]
setwd('I:/gbaccident0516/')
veh <- read.csv('veh2005_2016-v2018.2.5-tobeimp.csv')
library(mice)
library(dpltr)
library(dplyr)
library(parallel)
acc <- read.csv('acc2005_2015-v2018-2.5.imp.csv')
########################################
library(parallel)
cores_2_use <- detectCores() - 3
cl <- makeCluster(cores_2_use)
#########################################
# Impute function
fun_imp <- function(cl, data, X = 1:detectCores() - 2, m = 1, imp_meth, pred_mat, maxit = 5) {
imp_data <- data[[1]][c(),]
imp_merge <<- vector(mode = 'list', length = length(data))
print('Start Imputation')
for (n in 1:length(data)) {
imp_pairs <- parLapply(cl = cl, X = X, fun = function(no, d, m, method, predictionMatrix, maxit) {
mice(d, m = m, printFlag = FALSE, method = method, maxit = maxit, predictorMatrix = predictionMatrix)
}, data[[n]], m, imp_meth, pred_mat, maxit)
imp_merge[[n]] <<- imp_pairs[[1]]
for (p in 2:length(imp_pairs)) {
imp_merge[[n]] <<- ibind(imp_merge[[n]], imp_pairs[[p]])
}
imp_data <- rbind(imp_data, complete(imp_merge[[n]]))
gc()
print(n)
}
return (imp_data)
}
#########################################
# Split vehicles dataset into multiple years
fun_splt_veh <- function(data, tar) {
splt_veh <- list()
tar_names <- names(tar)
splt_veh[[tar_names[1]]] <- data[data$Accident_Index %in% tar[[1]]$Accident_Index, 2:ncol(data)]
for (n in 2:length(tar)) {
splt_veh[[tar_names[n]]] <- data[data$Accident_Index %in% tar[[n]]$Accident_Index, 2:ncol(data)]
}
return (splt_veh)
}
#########################################
# Wrapper function to write data to csv file
fun_imp_wrapper <- function(cl, data, file_name, cluster_export_varname, seed = 500, exclude = data.frame(), m = 1, cores_2_use = detectCores() - 2, imp_meth, pred_mat, maxit = 5, rdsexp = NA) {
if(nrow(exclude) > 0 && (nrow(exclude) != sum(sapply(data, nrow)))) {
print('Unbindable data & exclusion rows')
stopCluster(cl)
return
}
library(mice)
library(dplyr)
clusterSetRNGStream(cl, seed)
clusterExport(cl, cluster_export_varname)
clusterEvalQ(cl, library(mice))
imp_data <- fun_imp(cl = cl, data = data, X = 1:cores_2_use, m = m, imp_meth = imp_meth, pred_mat = pred_mat, maxit = maxit)
stopCluster(cl)
if(nrow(exclude) > 0)
imp_data_full <- bind_cols(imp_data, exclude)
write.csv(x = imp_data_full, file = paste0(file_name, '.imp.csv'), row.names = FALSE)
if(!is.na(rdsexp))
saveRDS(imp_merge, paste0(rdsexp, '.RData'))
}
########################################
veh[veh == -1] <- NA
summary(veh)
acc <- acc[, c('Accident_Index', 'Year')]
acc <- split(acc, acc$Year)
fun_splt_veh(veh, acc)
summary(veh)
excl <- veh[, c(1, 8:9)]
veh <- veh[, !(names(veh) %in% names(excl))]
veh <- excl[, 1]
rm(veh)
veh <- read.csv('veh2005_2016-v2018.2.5-tobeimp.csv')
veh <- veh[, 1:7]
veh <- fun_splt_veh(veh, acc)
veh <- lapply(veh, function(x) as.data.frame(lapply(x, factor)))
imp <- mice(bind_rows(veh), maxit=0)
warnings()
meth <- imp$method
predmat <- imp$predictorMatrix
meth
veh <- read.csv('veh2005_2016-v2018.2.5-tobeimp.csv')
veh <- veh[, 1:7]
veh[veh == -1] <- NA
summary(veh)
veh <- fun_splt_veh(veh, acc)
veh <- lapply(veh, function (x) as.data.frame(lapply(x, factor)))
imp <- mice(bind_rows(veh), maxit=0)
meth <- imp$method
predmat <- imp$predictorMatrix
meth
predmat
predmat
predmat[2, c(4, 3)] <- 0
predmat[4, c(1, 2, 3)] <- 0
predmat[5, c(3, 6)] <- 0
predmat[6, c(1, 3, 5, 6)] <- 0
predmat
rm(imp)
gc()
fun_imp_wrapper(cl = cl, data = veh, file_name = 'veh2005_2015-v2018-2.5', cluster_export_varname = 'veh', seed = sample(999999999, 1), exclude = excl, m = 2, cores_2_use = cores_2_use, imp_meth = meth, pred_mat = predmat, maxit = 10, rdsexp = 'veh_imp-v2018-2.5')
stopCluster(cl)
imp_merge[[3]]
imp_merge[[4]]
fun_imp
fun_imp <- function(cl, data, X = 1:detectCores() - 2, m = 1, imp_meth, pred_mat, maxit = 5) {
imp_data <- data[[1]][c(),]
imp_merge <<- vector(mode = 'list', length = length(data))
print('Start Imputation')
for (n in 4:length(data)) {
imp_pairs <- parLapply(cl = cl, X = X, fun = function(no, d, m, method, predictionMatrix, maxit) {
mice(d, m = m, printFlag = FALSE, method = method, maxit = maxit, predictorMatrix = predictionMatrix)
}, data[[n]], m, imp_meth, pred_mat, maxit)
imp_merge[[n]] <<- imp_pairs[[1]]
for (p in 2:length(imp_pairs)) {
imp_merge[[n]] <<- ibind(imp_merge[[n]], imp_pairs[[p]])
}
gc()
print(n)
}
return (imp_data)
}
fun_imp <- function(cl, data, X = 1:detectCores() - 2, m = 1, imp_meth, pred_mat, maxit = 5) {
imp_data <- data[[1]][c(),]
print('Start Imputation')
for (n in 4:length(data)) {
imp_pairs <- parLapply(cl = cl, X = X, fun = function(no, d, m, method, predictionMatrix, maxit) {
mice(d, m = m, printFlag = FALSE, method = method, maxit = maxit, predictorMatrix = predictionMatrix)
}, data[[n]], m, imp_meth, pred_mat, maxit)
imp_merge[[n]] <<- imp_pairs[[1]]
for (p in 2:length(imp_pairs)) {
imp_merge[[n]] <<- ibind(imp_merge[[n]], imp_pairs[[p]])
}
gc()
print(n)
}
for(n in 1:length(data)) {
imp_data <- rbind(imp_data, complete(imp_merge[[n]]))
}
return (imp_data)
}
cl <- makeCluster(cores_2_use)
gc()
fun_imp_wrapper(cl = cl, data = veh, file_name = 'veh2005_2015-v2018-2.5', cluster_export_varname = 'veh', seed = sample(999999999, 1), exclude = excl, m = 2, cores_2_use = cores_2_use, imp_meth = meth, pred_mat = predmat, maxit = 10, rdsexp = 'veh_imp-v2018-2.5')
cl <- makeCluster(cores_2_use)
fun_imp
fun_imp <- function(cl, data, X = 1:detectCores() - 2, m = 1, imp_meth, pred_mat, maxit = 5) {
imp_data <- data[[1]][c(),]
print('Start Imputation')
for (n in 8:length(data)) {
imp_pairs <- parLapply(cl = cl, X = X, fun = function(no, d, m, method, predictionMatrix, maxit) {
mice(d, m = m, printFlag = FALSE, method = method, maxit = maxit, predictorMatrix = predictionMatrix)
}, data[[n]], m, imp_meth, pred_mat, maxit)
imp_merge[[n]] <<- imp_pairs[[1]]
for (p in 2:length(imp_pairs)) {
imp_merge[[n]] <<- ibind(imp_merge[[n]], imp_pairs[[p]])
}
gc()
print(n)
}
for(n in 1:length(data)) {
imp_data <- rbind(imp_data, complete(imp_merge[[n]]))
}
return (imp_data)
}
imp_merge[[7]]
imp_merge[[8]]
fun_imp_wrapper(cl = cl, data = veh, file_name = 'veh2005_2015-v2018-2.5', cluster_export_varname = 'veh', seed = sample(999999999, 1), exclude = excl, m = 2, cores_2_use = cores_2_use, imp_meth = meth, pred_mat = predmat, maxit = 10, rdsexp = 'veh_imp-v2018-2.5')
gc()
dir()
plot(imp_merge[[10]])
densityplot(imp_merge[[10]], ~Vehicle_Manoevre + Junction_Location + Vehicle_Location_Restricted_Lane + Vehicle_Leaving_Carriageway + X1st_Point_of_Impact)
densityplot(imp_merge[[10]], ~Vehicle_Manoeuvre + Junction_Location + Vehicle_Location_Restricted_Lane + Vehicle_Leaving_Carriageway + X1st_Point_of_Impact)
densityplot(imp_merge[[10]], ~Vehicle_Manoeuvre + Junction_Location + Vehicle_Location_Restricted_Lane + X1st_Point_of_Impact)
names(imp_merge)
names(imp_merge[[1]])
imp_merge[[1]]$where
names(imp_merge[[1]])
imp_merge[[1]]$call
imp_merge[[1]]$nmiw
imp_merge[[1]]$nmis
imp_merge[[1]]$post
imp_merge[[1]]$pad
plot(imp_merge[[1]]$chainMean)
plot(imp_merge[[1]])
