demo()
graphics.table
graphics
demo(graphics)
smooth
par
cd
bar
plot
cls
clear
clean
sessionInfo()
graphics.graphics
graphics.image
plot(graphics.off())
Japanese()
Japanese
demo(graphics.Japanese)
demo(Japanese)
nlm()
help nlm
smooth
nlm
clean
clear
cls
empty
box
plot
histogram
hist
taylor
ts
matrix
byte
int
integer
string
str
float
double
Float
bigint
largeint
smallint
mini
max
min
max(4, 5)
max(4, 5, 22)
min(max(8, 11), avg(45, 55, 1, 2))
average
avg
avrg
min(max(8, 11), mean(45, 55, 1, 2))
mena
mean
quartile
quart
quar
vim
ggplot
shiny
exit
rshiny
vecp = rpois(100,5)
vecp = rpois(100,5)
vecp = rpois(100,5)
mean(vecp)
mean(vecp)
vecp = rpois(100,5)
mean(vecp)
rpois
lambda
set.seed(198911)
vecp = rpois(100,5)
mean(vecp)
vecp = rpois(100,5)
mean(vecp)
reps <- 5000
nexps <- 5
rate <- .1
set.seed(0)
system.time(x1 <- replicate(reps, sum(rexp(n=nexpsm rate=rate))))
system.time(x1 <- replicate(reps, sum(rexp(n=nexpsm, rate=rate))))
head(x1)
system.time(x1 <- replicate(reps, sum(rexp(n=nexpsm, rate=rate))))
qqplot
head
require(parallel)
system.time(x1 <- mclapply(1:reps, function(i) {}))
system.time(x1 <- mclapply(1:reps, function(i) {sum(rexp(n-nexps, rate=rate))}))
system.time(x1 <- mclapply(1:reps, function(i) {sum(rexp(n=nexps, rate=rate))}))
head(x1)
require(Biostrings)
install.packages("Biostrings")
require(MASS)
exit
quit
quit()
library(ggplot)
install.packages("ggplot, leaflet")
install.packages(ggplot)
install.packages("ggplot")
install.packages("leaflet")
plot
ggplot
version
library(readr)
train <- read_csv("D:/Download Placement/New folder/train.csv")
View(train)
ggplot2
install.packages(ggplot2)
install.packages("ggplot2")
dplyr
install.packages("shiny")
install.packages("data.table")
install.packages("zoo")
library("leaflet")
version
updare
update()
install.packages(c("haven", "R6", "Rcpp", "readr", "tibble"))
install.packages()
install.packages("installr")
library(installr)
updateR
updateR()
pathto
pathtor
install.packages("ggplot2")
install.packages("installr, ggplot2, dplyr, leaflet, zoo, data.table, R.matlab, matrix")
library(ggplot2)
install.packages("ggplot2")
install.packages("leaflet")
install.packages("dplyr")
install.packages("installr")
install.packages("zoo")
install.packages("data.tables")
install.packages("R.matlab")
install.packages("matrix")
install.packages("Matrix")
clc
clear
cls
clean
exit
quit()
setwd("D:\My Documents Placement\Dataset\Kaggle\UK_Car_Accidents_1979-2016")
install.packages("randomForest")
install.packages("party")
iris
print(head(iris))
library(randomForest)
library(party)
rf <- randomForest(Species ~ Sepal.length + Sepal.width + Petal.Length + Petal.Width, data = iris)
rf <- randomForest(Species ~ Sepal.Length + Sepal.Width + Petal.Length + Petal.Width, data = iris)
print(rf)
print(importance(fit, type = 2))
install.packages("neuralnet, leaflet")
install.packages("neuralnet")
install.packages("leaflet")
library(installr)
installr()
installr()
sample
help(sample)
help(iris)
help(iris3)
iris3
hist
hist(iris)
Sepal.length
Sepal.Length
iris.Sepal.Length
s <- sample(iris)
count.fields(iris)
length(iris)
length(s)
r(iris)
row
row(iris)
s <- sample(iris, .8)
s <- sample(iris, 100)
s <- sample(iris, 4)
s <- sample(iris, 2)
s <- sample(iris, 5)
remove(s)
tree
trees
decision
plot()
ir <- iris
remove(ir)
plot(iris$Sepal.Length, iris$Petal.Length)
help(hist)
wd
help("scatter.smooth")
help("sunflowerplot")
sunflowerplot(x = iris$Sepal.Length, y = iris$Sepal.Width)
sunflowerplot(x = iris$Sepal.Length)
sunflowerplot(x = iris$Sepal.Widt)
sunflowerplot(x = iris$Sepal.Width)
sunflowerplot(x = iris$Petal.Length)
sunflowerplot(x = iris$Petal.Width)
libra
library(party)
help(ctree)
col(iris)
head(iris)
ctree(formula = Species ~ Petal.Length + Petal.Width, data = iris)
plot(ctree(formula = Species ~ Petal.Length + Petal.Width, data = iris))
library(caret)
install.packages("caret")
devtools::install_github("rstudio/keras")
install.packages("devtools")
devtools::install_github("rstudio/keras")
devtools::install_github("rstudio/keras")
library(RTools)
devtools::install_github("rstudio/keras")
remove.packages(keras)
remove.packages(:)
remove.packages("keras")
load("~/Dataset/UK_Car_Accidents_1979-2016/alldataloaded_proccessed.RData")
common <- intersect(Accidents2016, Casualties2016)
remove(common)
cac2016 <- intersect(Accidents2016$Accident_Index, Casualties2016$Accident_Index)
cac2016
cav2016 <- intersect(Accidents2016, Vehicles2016)
remove(cav2016)
cav2016 <- intersect(Accidents2016$Accident_Index, Vehicles2016$Accident_Index)
c2016 <- intersect(cac2016, cav2016)
c2016
install.packages('dplyr')
quit
quit()
x <- c(0,0,0,0,1,1,1,1,1,1,1,2,2,2,2,3,3,3,0,0,0,0)
p <- matrix(nrow = 4, ncol = 4, 0)
for (t in 1:(length(x) - 1)) p[x[t], x[t + 1]] <- p[x[t], x[t + 1]] + 1
for (i in 1:4) p[i, ] <- p[i, ] / sum(p[i, ])
p
x <- c(0,0,0,0,1,1,1,1,1,1,1,2,2,2,2,3,3,3,0,0,0,0)
p <- matrix(nrow = 4, ncol = 4, 0)
for (t in 1:(length(x) - 1)) p[x[t], x[t + 1]] <- p[x[t], x[t + 1]] + 1
for (i in 0:3) p[i, ] <- p[i, ] / sum(p[i, ])
p
p[1, ]
setwd('h:/gbaccident0516/')
acc <- read.csv('acc2005_2016-v2018.2.1-tobeimp.csv')
excl <- acc[, c('Accident_Index', 'Date_Time')]
acc <- acc[, !(names(acc) %in% names(excl))]
acc <- split(acc, acc$Year)
fun_imp <- function(cl, data, tar = NA, X = 1:detectCores() - 2, m = 1) {
imp_data <- data[[1]][c(),]
print('Start Imputation')
for (n in 1:length(data)) {
imp_pairs <- parLapply(cl = cl, X = X, fun = function(no, d) {
mice(d, m = m, printFlag = FALSE)
}, data[[n]])
imp_merge <- imp_pairs[[1]]
for (p in 2:length(imp_pairs)) {
imp_merge <- ibind(imp_merge, imp_pairs[[p]])
}
imp_data <- rbind(imp_data, complete(imp_merge))
print(n)
}
if (!is.na(tar)) {
tar_col <- names(tar)
for (q in 1:length(tar)) {
imp_data[[tar_col[q]]] <- tar[, q]
}
}
return (imp_data)
}
#########################################
# Split vehicles dataset into multiple years
fun_splt_veh <- function(data, tar) {
splt_veh <- list()
tar_names <- names(tar)
splt_veh[[tar_names[1]]] <- data[data$Accident_Index %in% tar[[1]]$Accident_Index, 2:ncol(data)]
for (n in 2:length(tar)) {
splt_veh[[tar_names[n]]] <- data[data$Accident_Index %in% tar[[n]]$Accident_Index, 2:ncol(data)]
}
return (splt_veh)
}
#########################################
# Wrapper function to write data to csv file
fun_imp_wrapper <- function(cl, data, file_name, exclude = data.frame(), tar = NA, m = 1, cores_2_use = detectCores() - 2, cluster_export_varname = 'tobeimp_data') {
library(mice)
library(dplyr)
imp_data <- fun_imp(cl = cl, data = data, tar = tar, X = 1:cores_2_use, m = m)
if(nrow(exclude) > 0)
imp_data_full <- bind_cols(imp_data, exclude)
print(names(imp_data))
print(names(imp_data_full))
write.csv(x = imp_data_full, file = paste0(file_name, '.imp.csv'), row.names = FALSE)
stopCluster(cl)
}
library(parallel)
cores_2_use <- detectCores() - 3
cl <- makeCluster(cores_2_use)
clusterSetRNGStream(cl, 500)
clusterExport(cl, 'acc')
clusterEvalQ(cl, library(mice))
stopCluster(cl)
tst_acc <- lapply(acc, function(x) x[1:10000,])
tst_excl <- excl[1:120000]
tst_excl <- excl[1:120000,]
cores_2_use <- detectCores() - 3
cl <- makeCluster(cores_2_use)
clusterSetRNGStream(cl, 500)
clusterExport(cl, 'tst_acc')
clusterEvalQ(cl, library(mice))
fun_imp_wrapper(cl = cl, data = tst_acc, file_name = 'tst_acc', exclude = tst_excl, m = 1, cores_2_use = cores_2_use)
fun_imp <- function(cl, data, tar = NA, X = 1:detectCores() - 2, m = 1) {
imp_data <- data[[1]][c(),]
print('Start Imputation')
for (n in 1:length(data)) {
imp_pairs <- parLapply(cl = cl, X = X, fun = function(no, d) {
mice(d, m = m, printFlag = FALSE)
}, data[[n]])
imp_merge <- imp_pairs[[1]]
for (p in 2:length(imp_pairs)) {
imp_merge <- ibind(imp_merge, imp_pairs[[p]])
}
imp_data <- rbind(imp_data, complete(imp_merge))
print(n)
}
if (!is.na(tar)) {
tar_col <- names(tar)
for (q in 1:length(tar)) {
imp_data[[tar_col[q]]] <- tar[, q]
}
}
return (imp_data)
}
#########################################
# Split vehicles dataset into multiple years
fun_splt_veh <- function(data, tar) {
splt_veh <- list()
tar_names <- names(tar)
splt_veh[[tar_names[1]]] <- data[data$Accident_Index %in% tar[[1]]$Accident_Index, 2:ncol(data)]
for (n in 2:length(tar)) {
splt_veh[[tar_names[n]]] <- data[data$Accident_Index %in% tar[[n]]$Accident_Index, 2:ncol(data)]
}
return (splt_veh)
}
#########################################
# Wrapper function to write data to csv file
fun_imp_wrapper <- function(cl, data, file_name, cluster_export_varname, seed = 500, exclude = data.frame(), tar = NA, m = 1, cores_2_use = detectCores() - 2) {
library(mice)
library(dplyr)
clusterSetRNGStream(cl, seed)
clusterExport(cl, cluster_export_varname)
clusterEvalQ(cl, library(mice))
imp_data <- fun_imp(cl = cl, data = data, tar = tar, X = 1:cores_2_use, m = m)
if(nrow(exclude) > 0)
imp_data_full <- bind_cols(imp_data, exclude)
write.csv(x = imp_data_full, file = paste0(file_name, '.imp.csv'), row.names = FALSE)
stopCluster(cl)
}
library(parallel)
cores_2_use <- detectCores() - 3
cl <- makeCluster(cores_2_use)
fun_imp_wrapper(cl = cl, data = tst_acc, file_name = 'tst_acc', cluster_export_varname = 'tst_acc', seed = 500, exclude = excl, cores_2_use = cores_2_use)
fun_imp_wrapper(cl = cl, data = tst_acc, file_name = 'tst_acc', cluster_export_varname = 'tst_acc', seed = 500, exclude = tst_excl, cores_2_use = cores_2_use)
nrow(tst_acc)
nrow(unsplit(tst_acc))
length(tst_acc)
length(tst_excl)
nrow(tst_excl)
nrow(tst_acc)
sum(lapply(tst_acc, function(x) length(x)))
lapply(tst_acc, function(x) length(x))
lapply(tst_acc, function(x) nrow(x))
sum(lapply(tst_acc, function(x) nrow(x)))
lapply(lapply(tst_acc, function(x) nrow(x)), function(x) sum(x))
lapply(tst_acc, function(x) nrow(x))
sapply(lapply(tst_acc, function(x) nrow(x)), sum)
sum(sapply(tst_acc, sum))
sapply(tst_acc, sum)
sum(sapply(tst_acc, nrow))
fun_imp_wrapper <- function(cl, data, file_name, cluster_export_varname, seed = 500, exclude = data.frame(), tar = NA, m = 1, cores_2_use = detectCores() - 2) {
if(nrow(exclude) > 0 && (nrow(exclude) == sum(sapply(data, nrow))))
library(mice)
library(dplyr)
clusterSetRNGStream(cl, seed)
clusterExport(cl, cluster_export_varname)
clusterEvalQ(cl, library(mice))
imp_data <- fun_imp(cl = cl, data = data, tar = tar, X = 1:cores_2_use, m = m)
if(nrow(exclude) > 0)
imp_data_full <- bind_cols(imp_data, exclude)
write.csv(x = imp_data_full, file = paste0(file_name, '.imp.csv'), row.names = FALSE)
stopCluster(cl)
}
fun_imp_wrapper <- function(cl, data, file_name, cluster_export_varname, seed = 500, exclude = data.frame(), tar = NA, m = 1, cores_2_use = detectCores() - 2) {
if(nrow(exclude) > 0 && (nrow(exclude) != sum(sapply(data, nrow)))) {
print('Unbindable data & exclusion rows')
stopCluster(cl)
return
}
library(mice)
library(dplyr)
clusterSetRNGStream(cl, seed)
clusterExport(cl, cluster_export_varname)
clusterEvalQ(cl, library(mice))
imp_data <- fun_imp(cl = cl, data = data, tar = tar, X = 1:cores_2_use, m = m)
if(nrow(exclude) > 0)
imp_data_full <- bind_cols(imp_data, exclude)
write.csv(x = imp_data_full, file = paste0(file_name, '.imp.csv'), row.names = FALSE)
stopCluster(cl)
}
fun_imp_wrapper(cl = cl, data = tst_acc, file_name = 'tst_acc', cluster_export_varname = 'tst_acc', seed = 500, exclude = excl, cores_2_use = cores_2_use)
cores_2_use <- detectCores() - 3
cl <- makeCluster(cores_2_use)
fun_imp_wrapper(cl = cl, data = tst_acc, file_name = 'tst_acc', cluster_export_varname = 'tst_acc', seed = 500, exclude = excl, cores_2_use = cores_2_use)
cores_2_use <- detectCores() - 3
cl <- makeCluster(cores_2_use)
fun_imp_wrapper(cl = cl, data = tst_acc, file_name = 'tst_acc', cluster_export_varname = 'tst_acc', seed = 500, exclude = tst_excl, cores_2_use = cores_2_use)
?unsplit
acc.isnull()
any(is.na(acc))
is.na(acc)
acc <- read.csv('acc2005_2016-v2018.2.1-tobeimp.csv')
acc[acc == -1] <- -1
acc[acc == -1] <- NA
any(is.na(acc))
acc <- split(acc, acc$Year)
